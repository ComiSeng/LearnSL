% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/decission_tree.R
\name{decision_tree}
\alias{decision_tree}
\title{Decision Tree}
\usage{
decision_tree(data, classy, m, method = "entropy")
}
\arguments{
\item{data}{A data frame with already classified observations. Each column
represents a parameter of the value. Each row is a different observation.
The column names in the parameter "data" must not contain the
sequence of characters " or ".
As this is supposed to be a binary decision rules generator and not a binary
decision tree generator, no tree structures are used, except for the
information gain formulas.}

\item{classy}{Name of the column we want the data to be classified by.
the set of rules obtained will be calculated according to this.}

\item{m}{Maximum numbers of child nodes each node can have.}

\item{method}{The definition of Gain. It must be one of
\code{"Entropy"}, \code{"Gini"}or \code{"Error"}.}
}
\value{
data frame with a list of steps used to classify the data with this
columns:
Classifier  Value   Classified
}
\description{
This function creates a set of rules needed to classify data,
calculating the best classifier possible in each step. Only creates perfect
divisions, this means, if the rule doesn't create a classified group, it is
not considered.
}
\details{
Available gain information methods are:

\describe{
 * \emph{Entropy}: The formula to calculate the information gain
 works as follows: \deqn{p = -\sum{fi p\sub i * \log2 p\sub i}}
}
}
\author{
VÃ­ctor Amador Padilla
}
\keyword{classification,}
\keyword{decision}
\keyword{gain}
\keyword{information}
\keyword{learning,}
\keyword{rules,}
\keyword{supervised}
