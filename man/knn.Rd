% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/knn.R
\name{knn}
\alias{knn}
\title{K-Nearest Neighbors}
\usage{
knn(data, p1, d_method = "euclidean", k, p = 3)
}
\arguments{
\item{data}{Data frame with already classified observations. Each
column represents a parameter of the values. The last column contains the
output, this means, the expected output when the other column values are
inputs. Each row is a different observation.}

\item{p1}{Vector containing the parameters of the new value that we want to
clasify.}

\item{d_method}{String with the name of the distance method that will
be used. It must be one of \code{"Euclidean"}, \code{"Manhattan"},
\code{"Cosine"}, \code{"Chebyshev"}, \code{"Minkowski"}, \code{"Canberra"},
\code{"Octile"}, \code{"Hamming"}, \code{"Binary"}or \code{"Jaccard"}. Where
both \code{"Hamming"} and \code{"Binary"} use the same method, as it is known
by both names.}

\item{k}{Number of closest values that will be considered in order to clasify
the new value ("p1").}

\item{p}{Exponent used in the \code{Minkowski distance}. 3 by default,
otherwise if specified.}
}
\value{
Value of the new classified example.
}
\description{
This function applies knn algorith to clasify data.
}
\keyword{K-Nearest}
\keyword{Neighbors,}
\keyword{classification,}
\keyword{distance.}
\keyword{knn,}
\keyword{supervised}
